{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils import calculate_ious\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from model import YOLO\n",
    "from dataset import yolo_dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(56.5942, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = 4\n",
    "B = 1\n",
    "C = 1\n",
    "IMG_SIZE = 300\n",
    "\n",
    "class YOLO_LOSS(nn.Module):\n",
    "\n",
    "    def __init__(self, S, B, C, IMG_SIZE):\n",
    "        super(YOLO_LOSS, self).__init__()\n",
    "        r\"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.img_size = IMG_SIZE\n",
    "        self.mse = nn.MSELoss(reduction='sum')\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        r\"\"\"\n",
    "        Args: \n",
    "            predictions: vem no formato flatten. [N, S*S*5]\n",
    "            targets: vem no formato [S, S, 5]\n",
    "        \n",
    "        Returns: \n",
    "            loss: o somatório de todas as perdas, ponderadas.\n",
    "        \"\"\"\n",
    "        # aqui faz o reshape do predictions igual ao shape do target.\n",
    "        predictions = predictions.reshape(targets.shape)\n",
    "\n",
    "        # A variável exists_box é a que possui em qual célula está pre\n",
    "        # sente o objeto.\n",
    "        exists_box = targets[:, :, :, 0].unsqueeze(3)\n",
    "        no_exists_box = 1 - exists_box\n",
    "\n",
    "        # ======================= CALCULO PERDA PARA COORDENADAS =============================\n",
    "        # Aqui fazemos a multiplicação e pegamos as predições\n",
    "        # somente das células que de fato são responsáveis pelo objeto\n",
    "        box_predictions = exists_box * predictions[:, :, :, 1:]\n",
    "        box_targets = exists_box * targets[:, :, :, 1:]\n",
    "\n",
    "        # De acordo com a função perda do paper, o somatório de w e h\n",
    "        # é feito pelas suas raizes quadradas. Assim vamos alterar somente\n",
    "        # esses itens.\n",
    "\n",
    "        # aqui fazemos:                torch.sign para respeitar o sinal    # raiz quadrada do absoluto + 1e-6 para não dar erro\n",
    "        box_predictions[:,:,:,2:] = torch.sign(box_predictions[:,:,:,2:]) * torch.sqrt(torch.abs(box_predictions[:,:,:,2:] + 1e-6))\n",
    "        box_targets[:,:,:,2:] = torch.sign(box_targets[:,:,:,2:]) * torch.sqrt(torch.abs(box_targets[:,:,:,2:] + 1e-6))\n",
    "        # para esse segundo não é necessário, mas fez apenas para manter o padrão\n",
    "\n",
    "        box_loss = self.mse(box_predictions.reshape(-1, 4), box_targets.reshape(-1, 4))\n",
    "        # ======================= CALCULO PERDA PARA COORDENADAS =============================\n",
    "\n",
    "        # Como este problema só tem uma classe, então não temos cálculo de perdas\n",
    "        # para classes. Assim, vamos direto para última linha da função perda\n",
    "\n",
    "        # ====================== CALCULO PARA PROBABILIDADE DE DETECAÇÃO DE OBJETO ===========\n",
    "        prob_exists_prediction = exists_box * predictions[:,:,:,0].unsqueeze(3)\n",
    "        prob_exists_target = exists_box * targets[:,:,:,0].unsqueeze(3)\n",
    "        prob_exists_loss = self.mse(\n",
    "            prob_exists_prediction.reshape(-1, 1), \n",
    "            prob_exists_target.reshape(-1, 1)\n",
    "        )\n",
    "        # ====================== CALCULO PARA PROBABILIDADE DE DETECAÇÃO DE OBJETO ===========\n",
    "\n",
    "        # ================= CALCULO PARA PROBABILIDADE DE NÃO DETECAÇÃO DE OBJETO ============\n",
    "        prob_no_exists_prediction = no_exists_box * predictions[:,:,:,0].unsqueeze(3)\n",
    "        prob_no_exists_target = no_exists_box * targets[:,:,:,0].unsqueeze(3)\n",
    "        prob_noobj_loss = self.mse(\n",
    "            prob_no_exists_prediction.reshape(-1, 1),\n",
    "            prob_no_exists_target.reshape(-1, 1)\n",
    "        )\n",
    "        # ================= CALCULO PARA PROBABILIDADE DE NÃO DETECAÇÃO DE OBJETO ============\n",
    "        \n",
    "        loss = (\n",
    "            box_loss * self.lambda_coord\n",
    "            + prob_exists_loss\n",
    "            + prob_noobj_loss * self.lambda_noobj\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "model = YOLO(S, C, B, IMG_SIZE)\n",
    "yolo_loss = YOLO_LOSS(S, B, C, IMG_SIZE)\n",
    "df = pd.read_csv('annotations.csv')\n",
    "imgs_list = df['img_path'].unique()\n",
    "dataset = yolo_dataset(S, B, C, IMG_SIZE, imgs_list)\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "imgs_tensor, target_tensor = next(iter(dataloader))\n",
    "predictions = model(imgs_tensor)\n",
    "\n",
    "loss = yolo_loss(predictions, target_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa39838d5afd7d94b7544cb5e5351cace91d1e0eb74b6451fdb6f11f3a068bed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
